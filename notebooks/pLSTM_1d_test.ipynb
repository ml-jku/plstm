{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import torch\n",
        "\n",
        "from plstm.torch.plstm_1d import pLSTM1D_fwbw, pLSTM1D_torch\n",
        "from plstm.torch.test_utils import check_forward, check_backward\n",
        "from plstm.torch.util import log2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(x, dim=0):\n",
        "    y = x - torch.mean(x, dim=dim, keepdim=True)\n",
        "    return y / torch.sqrt(torch.mean(y**2, dim=dim, keepdim=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalize(torch.arange(5.0)[None, :], dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "B = 1\n",
        "T = 32\n",
        "BT = 8\n",
        "DHQK = 11\n",
        "DHHV = 5\n",
        "JQ = 1\n",
        "JT = 1\n",
        "JV = 1\n",
        "JK = 1\n",
        "JO = 1\n",
        "DTYPE = torch.float64\n",
        "\n",
        "rand_factor = 0.0\n",
        "Q = 1.0 + rand_factor * torch.randn([B, T, DHQK, JQ], dtype=DTYPE) / DHQK\n",
        "K = 1.0 + rand_factor * torch.randn([B, T, DHQK, JK], dtype=DTYPE)\n",
        "V = torch.randn([B, T, DHHV, JV], dtype=DTYPE) + 0.1 * torch.arange(JV * DHHV).reshape(1, 1, DHHV, JV)\n",
        "S0 = 0.1 + rand_factor * torch.randn([B, T, JT, JK, JV], dtype=DTYPE)\n",
        "T0 = torch.eye(JT)[None, None, :, :] * torch.ones([B, T, 1, 1], dtype=DTYPE)\n",
        "T0 = T0 + 0.01 * rand_factor * torch.randn_like(T0)\n",
        "M0 = 1.0 + rand_factor * torch.randn([B, T, JO, JQ, JT], dtype=DTYPE)\n",
        "D0 = 1.0 + rand_factor * torch.randn([B, T, JO, JQ, JK, JV], dtype=DTYPE)\n",
        "C_initial = 0.0 * torch.randn([B, DHQK, DHHV, JT], dtype=DTYPE)\n",
        "\n",
        "print(Q.shape)\n",
        "\n",
        "Q.requires_grad_(True)\n",
        "K.requires_grad_(True)\n",
        "V.requires_grad_(True)\n",
        "S0.requires_grad_(True)\n",
        "T0.requires_grad_(True)\n",
        "M0.requires_grad_(True)\n",
        "\n",
        "S0mag = (\n",
        "    0.01\n",
        "    # + 0.1* rand_factor * torch.randn([B, T])\n",
        "    - 0.1 * torch.arange(T)[None, :]\n",
        ")\n",
        "T0mag = (\n",
        "    -0.01 + 0.0 * 0.1 * rand_factor * 0.01 * torch.randn([B, T])\n",
        "    # + 0.01 * torch.arange(T)[None, :]\n",
        ")\n",
        "\n",
        "_ = \"\"\n",
        "# Y = pLSTM1D_fwbw(Q, K, V, S0, M0, T0, chunk_size=16)\n",
        "# Y = Y.reshape(B, T, DHHV * JQ)[0, :, 0]\n",
        "\n",
        "# Y.sum().backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "check_forward(\n",
        "    lambda q, k, v, s0, t0, m0, d0, c0: normalize(\n",
        "        pLSTM1D_torch(q, k, v, s0, t0, m0, d0, C_initial=c0, levels=log2(BT)),\n",
        "        dim=2,\n",
        "    ).flatten(2, 3),\n",
        "    lambda q, k, v, s0, t0, m0, d0, c0: normalize(\n",
        "        pLSTM1D_torch(q, k, v, s0, t0, m0, d0, C_initial=c0, levels=log2(BT // 2)),\n",
        "        dim=2,\n",
        "    ).flatten(2, 3),\n",
        "    (Q, K, V, S0, T0, M0, D0, C_initial),\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check_forward(\n",
        "#     lambda q, k, v, s0, t0, m0, d0, c0: pLSTM1D_torch(\n",
        "#         q, k, v, s0, t0, m0, d0, C_initial=c0, levels=log2(BT)\n",
        "#     ),\n",
        "#     lambda q, k, v, s0, t0, m0, d0, c0: pLSTM1D_fwbw(\n",
        "#         q, k, v, s0, t0, m0, d0, S0mag, T0mag, C_initial=c0, levels=log2(BT)\n",
        "#     ),\n",
        "#     (Q, K, V, S0, T0, M0, D0, C_initial),\n",
        "#     verbose=True,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "check_forward(\n",
        "    lambda q, k, v, s0, t0, m0, d0, s0m, t0m, c0: normalize(\n",
        "        pLSTM1D_torch(q, k, v, s0, t0, m0, d0, s0m, t0m, C_initial=c0, levels=log2(BT)),\n",
        "        dim=2,\n",
        "    ).flatten(2, 3),\n",
        "    lambda q, k, v, s0, t0, m0, d0, s0m, t0m, c0: normalize(\n",
        "        pLSTM1D_torch(q, k, v, s0, t0, m0, d0, s0m, t0m, C_initial=c0, levels=log2(BT // 2)),\n",
        "        dim=2,\n",
        "    ).flatten(2, 3),\n",
        "    (Q, K, V, S0, T0, M0, D0, S0mag, T0mag, C_initial),\n",
        "    verbose=True,\n",
        "    atol=1e-3,\n",
        "    rtol=1e-3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "check_forward(\n",
        "    lambda q, k, v, s0, t0, m0, d0, s0m, t0m, c0: normalize(\n",
        "        pLSTM1D_torch(q, k, v, s0, t0, m0, d0, s0m, t0m, C_initial=c0, levels=log2(BT)),\n",
        "        dim=2,\n",
        "    ).flatten(2, 3),\n",
        "    lambda q, k, v, s0, t0, m0, d0, s0m, t0m, c0: normalize(\n",
        "        pLSTM1D_fwbw(q, k, v, s0, t0, m0, d0, s0m, t0m, C_initial=c0, levels=log2(BT // 2)),\n",
        "        dim=2,\n",
        "    ).flatten(2, 3),\n",
        "    (Q, K, V, S0, T0, M0, D0, S0mag, T0mag, C_initial),\n",
        "    verbose=True,\n",
        "    atol=1e-3,\n",
        "    rtol=1e-3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "a = pLSTM1D_torch(\n",
        "    Q,\n",
        "    K,\n",
        "    V,\n",
        "    S0,\n",
        "    T0,\n",
        "    M0,\n",
        "    D0,\n",
        "    S0mag=S0mag,\n",
        "    T0mag=T0mag,\n",
        "    C_initial=C_initial,\n",
        "    levels=log2(BT),\n",
        ")\n",
        "a.sum().backward(retain_graph=True)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "return_last_C = False\n",
        "use_initial_C = True\n",
        "check_backward(\n",
        "    lambda q, k, v, s0, t0, m0, d0, c0: normalize(\n",
        "        pLSTM1D_torch(\n",
        "            q,\n",
        "            k,\n",
        "            v,\n",
        "            s0,\n",
        "            t0,\n",
        "            m0,\n",
        "            d0,\n",
        "            C_initial=c0,\n",
        "            levels=log2(BT),\n",
        "            return_last_C=return_last_C,\n",
        "        ).flatten(2, 3),\n",
        "        dim=2,\n",
        "    ),\n",
        "    lambda q, k, v, s0, t0, m0, d0, c0: normalize(\n",
        "        pLSTM1D_fwbw(\n",
        "            q,\n",
        "            k,\n",
        "            v,\n",
        "            s0,\n",
        "            t0,\n",
        "            m0,\n",
        "            d0,\n",
        "            C_initial=c0,\n",
        "            levels=log2(BT),\n",
        "            recompute_C=True,\n",
        "            recompute_G=True,\n",
        "            use_initial_C=use_initial_C,\n",
        "            return_last_C=return_last_C,\n",
        "        ).flatten(2, 3),\n",
        "        dim=2,\n",
        "    ),\n",
        "    (Q, K, V, S0, T0, M0, D0, C_initial if use_initial_C else None),\n",
        "    verbose=True,\n",
        "    rand_factor=1.0,\n",
        "    atol=1e-4,\n",
        "    rtol=1e-2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "return_last_C = False\n",
        "use_initial_C = True\n",
        "check_backward(\n",
        "    lambda q, k, v, s0, t0, m0, d0, sm, tm, c0: normalize(\n",
        "        pLSTM1D_torch(\n",
        "            q,\n",
        "            k,\n",
        "            v,\n",
        "            s0,\n",
        "            t0,\n",
        "            m0,\n",
        "            d0,\n",
        "            sm,\n",
        "            tm,\n",
        "            C_initial=c0,\n",
        "            levels=log2(BT) // 2,\n",
        "            return_last_C=return_last_C,\n",
        "        ),\n",
        "        dim=2,\n",
        "    ).flatten(2, 3),\n",
        "    lambda q, k, v, s0, t0, m0, d0, sm, tm, c0: normalize(\n",
        "        pLSTM1D_fwbw(\n",
        "            q,\n",
        "            k,\n",
        "            v,\n",
        "            s0,\n",
        "            t0,\n",
        "            m0,\n",
        "            d0,\n",
        "            sm,\n",
        "            tm,\n",
        "            C_initial=c0,\n",
        "            levels=log2(BT),\n",
        "            use_initial_C=use_initial_C,\n",
        "            # recompute_C=False,\n",
        "            # recompute_G=False,\n",
        "            return_last_C=return_last_C,\n",
        "        ),\n",
        "        dim=2,\n",
        "    ).flatten(2, 3),\n",
        "    (Q, K, V, S0, T0, M0, D0, S0mag, T0mag, C_initial if use_initial_C else None),\n",
        "    verbose=True,\n",
        "    rand_factor=1.0,\n",
        "    atol=1e-4,\n",
        "    rtol=5e-2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from plstm.torch.plstm_1d_layer import pLSTM1DLayer, pLSTM1DLayerConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "D = 512\n",
        "H = 4\n",
        "JK = JQ = 1\n",
        "JV = JO = JT = 4\n",
        "\n",
        "plstm = (\n",
        "    pLSTM1DLayer(\n",
        "        pLSTM1DLayerConfig(\n",
        "            DK=D // JK,\n",
        "            num_heads=H,\n",
        "            DV=D // JV,\n",
        "            JQ=JQ,\n",
        "            JK=JK,\n",
        "            JV=JV,\n",
        "            JT=JT,\n",
        "            JO=JO,\n",
        "            input_dim=D,\n",
        "            sub_heads=16,\n",
        "        )\n",
        "    )\n",
        "    .to(device=device)\n",
        "    .to(dtype=torch.float16)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "B, T = 3, 2048\n",
        "\n",
        "o = plstm(torch.randn([B, T, H * D], device=device, dtype=torch.float16) * D ** (-1 / 2))\n",
        "print(o.shape)\n",
        "print(torch.max(o))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "o = plstm(torch.randn([B, T, H * D], device=device, dtype=torch.float16) * D ** (-1 / 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "o.sum().backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plstm_tc = torch.compile(plstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "o2 = plstm_tc(torch.randn([B, T, H * D], device=device, dtype=torch.float16) * D ** (-1 / 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "o3 = plstm_tc(torch.randn([B, T, H * D], device=device, dtype=torch.float16) * D ** (-1 / 2))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "plstm_pt251jax0434cu124py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
